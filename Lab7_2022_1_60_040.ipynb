{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbAflxEpxISa",
        "outputId": "22bc0f7f-85f3-4204-ecae-a29858c97590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch torchvision scikit-learn matplotlib grad-cam"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyGpBu3BwjFb",
        "outputId": "9334af74-3629-41f5-d356-de6e0c07cce9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Collecting grad-cam\n",
            "  Downloading grad-cam-1.5.4.tar.gz (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Collecting ttach (from grad-cam)\n",
            "  Downloading ttach-0.0.3-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from grad-cam) (4.67.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from grad-cam) (4.10.0.84)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n",
            "Building wheels for collected packages: grad-cam\n",
            "  Building wheel for grad-cam (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for grad-cam: filename=grad_cam-1.5.4-py3-none-any.whl size=39648 sha256=1e7277c08fa21087f1220caf86025b7f08dbf8ebdd9ba3aecf7aa554c96a3402\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/b0/82/1f97b5348c7fe9f0ce0ba18497202cafa5dec4562bd5292680\n",
            "Successfully built grad-cam\n",
            "Installing collected packages: ttach, grad-cam\n",
            "Successfully installed grad-cam-1.5.4 ttach-0.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "https://drive.google.com/file/d/1krplHcJqXsQ7Yxk9gaAAs49Pc3DcnJML/view?usp=sharing"
      ],
      "metadata": {
        "id": "07cJUvx0UgXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = \"1krplHcJqXsQ7Yxk9gaAAs49Pc3DcnJML\"\n",
        "!gdown \"https://drive.google.com/uc?id={file_id}\" -O caltech-101.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iH2CdEGUTt8f",
        "outputId": "59fcec47-f0a7-4bdf-e74e-fc4bbf112ff1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1krplHcJqXsQ7Yxk9gaAAs49Pc3DcnJML\n",
            "From (redirected): https://drive.google.com/uc?id=1krplHcJqXsQ7Yxk9gaAAs49Pc3DcnJML&confirm=t&uuid=8199341a-6886-4bce-8842-7b9f4da132d8\n",
            "To: /content/caltech-101.zip\n",
            "100% 137M/137M [00:04<00:00, 29.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q caltech-101.zip -d .\n"
      ],
      "metadata": {
        "id": "yhMTpTT0w0ep"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "N-UCpZhnvWEl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cyLhBjnJKtBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paths and Settings"
      ],
      "metadata": {
        "id": "vPy90bDZghpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_dir = \"/content/caltech-101\"\n",
        "batch_size = 32\n",
        "num_classes = 101\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "lTheFw2fKrRv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Loading and Transformations"
      ],
      "metadata": {
        "id": "ph4s-SDwgkrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
        "num_classes = len(dataset.classes)  # Automatically detect the number of classes\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = int(0.1 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "train_data, val_data, test_data = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "jvjRMZsvKpIF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Selector"
      ],
      "metadata": {
        "id": "6MdAcSgvgoVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def select_model(model_name):\n",
        "    if model_name == \"resnet50\":\n",
        "        model = models.resnet50(pretrained=True)\n",
        "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    elif model_name == \"vgg19\":\n",
        "        model = models.vgg19(pretrained=True)\n",
        "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
        "    elif model_name == \"efficientnet_b0\":\n",
        "        model = models.efficientnet_b0(pretrained=True)\n",
        "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported model name\")\n",
        "    return model.to(device)\n"
      ],
      "metadata": {
        "id": "ds83rFaxKl63"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select Pre-trained Model"
      ],
      "metadata": {
        "id": "YRSJpiZQgqdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_name = \"resnet50\"  # Change to \"vgg19\" or \"efficientnet_b0\" as needed\n",
        "model = select_model(model_name)"
      ],
      "metadata": {
        "id": "-W3mBdykKjOd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b073d4cd-af59-4cac-f350-4ae2f90e5920"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss and Optimizer"
      ],
      "metadata": {
        "id": "hnvDwI6kgtHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "gdVTEXkqKgDa"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Loop"
      ],
      "metadata": {
        "id": "Sw8z2VyRgu8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
        "    best_val_acc = 0.0\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        train_acc = correct / total\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/total:.4f}, Accuracy: {train_acc:.4f}\")\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                correct += (preds == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "        val_acc = correct / total\n",
        "        print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), \"best_model.pth\")\n",
        "\n",
        "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs)"
      ],
      "metadata": {
        "id": "rSwTVBypKYHt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4575e9fd-1d44-4b3e-e7fe-1a6c785167d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Loss: 3.4727, Accuracy: 0.2835\n",
            "Validation Accuracy: 0.3720\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Best Model"
      ],
      "metadata": {
        "id": "4Vsx6B2vgw91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.load_state_dict(torch.load(\"best_model.pth\"))"
      ],
      "metadata": {
        "id": "Njfj9k6SKLUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grad-CAM Visualization"
      ],
      "metadata": {
        "id": "I22ZufXOg0wQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def grad_cam_visualization(model, test_loader):\n",
        "    target_layer = model.layer4[-1] if hasattr(model, 'layer4') else model.features[-1]  # Adjust based on architecture\n",
        "    cam = GradCAM(model=model, target_layer=target_layer, use_cuda=(device.type == 'cuda'))\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(test_loader):\n",
        "        if i >= 5:  # Limit to 5 visualizations\n",
        "            break\n",
        "        inputs = inputs.to(device)\n",
        "        grayscale_cam = cam(input_tensor=inputs)\n",
        "        for j in range(inputs.size(0)):\n",
        "            img = inputs[j].cpu().permute(1, 2, 0).numpy()\n",
        "            img = (img * 0.229 + 0.485).clip(0, 1)  # Reverse normalization\n",
        "            cam_image = show_cam_on_image(img, grayscale_cam[j], use_rgb=True)\n",
        "            plt.imshow(cam_image)\n",
        "            plt.title(f\"Label: {labels[j]} Prediction: {torch.argmax(model(inputs[j:j+1]), 1).item()}\")\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "\n",
        "grad_cam_visualization(model, test_loader)\n"
      ],
      "metadata": {
        "id": "6BLERcP6KI3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grad-CAM Visualization"
      ],
      "metadata": {
        "id": "09ao9W7Ug2X8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(preds.cpu().numpy())\n",
        "\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=dataset.classes, yticklabels=dataset.classes)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "tbI9O6GJKGXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(model, test_loader)"
      ],
      "metadata": {
        "id": "ZVL1g4G4KC5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grad-CAM\n",
        "def grad_cam_test(model, image_path):\n",
        "    target_layer = model.layer4[-1] if hasattr(model, 'layer4') else model.features[-1]\n",
        "    cam = GradCAM(model=model, target_layer=target_layer, use_cuda=(device.type == 'cuda'))\n",
        "\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    input_tensor = transform(image).unsqueeze(0).to(device)  # Apply the same transformations\n",
        "\n",
        "    grayscale_cam = cam(input_tensor=input_tensor)[0]\n",
        "    img = input_tensor[0].cpu().permute(1, 2, 0).numpy()\n",
        "    img = (img * 0.229 + 0.485).clip(0, 1)  # Reverse normalization\n",
        "    cam_image = show_cam_on_image(img, grayscale_cam, use_rgb=True)\n",
        "\n",
        "    plt.imshow(cam_image)\n",
        "    plt.title(\"Grad-CAM Visualization\")\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "MCshZrl-Y3MV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Usage\n",
        "grad_cam_test(model, \"path_to_image.jpg\")  # Replace with the actual image path"
      ],
      "metadata": {
        "id": "NW9EWL6WYRVy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}